{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.dynamics import Lorenz96\n",
    "from src.measurements import Linear\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "dim = 20\n",
    "prior_mean = 2.0\n",
    "prior_std = 1.0\n",
    "dt = 0.05\n",
    "forcing = 8.0\n",
    "perturb_std = 0.1\n",
    "solver = \"Runge-Kutta\"\n",
    "steps = 100\n",
    "\n",
    "noise_std = 0.5\n",
    "\n",
    "n_ensemble = 500\n",
    "n_resampling = n_ensemble\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "dynamics = Lorenz96(\n",
    "    dim=dim,\n",
    "    prior_mean=prior_mean,\n",
    "    prior_std=prior_std,\n",
    "    dt=dt,\n",
    "    forcing=forcing,\n",
    "    perturb_std=perturb_std,\n",
    "    solver=solver,\n",
    ")\n",
    "\n",
    "measurement = Linear(noise_std=noise_std)\n",
    "\n",
    "x0 = forcing * torch.ones((1, dim), device=device)  # (1, dim)\n",
    "x0[0][0] += 0.01\n",
    "\n",
    "states: torch.Tensor = dynamics.generate(\n",
    "    x0=x0,\n",
    "    steps=steps,\n",
    ")  # (steps+1, dim)\n",
    "observations: torch.Tensor = measurement.measure(states) # (steps+1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = torch.empty((steps+1, n_ensemble, dim), device=device)\n",
    "ensembles[0] = torch.randn((n_ensemble, dim)) * prior_std + prior_mean\n",
    "\n",
    "for i in range(steps):\n",
    "    # mu = dynamics.transition(ensembles[i])\n",
    "    mu = dynamics.transition(ensembles[i]) + torch.randn_like(ensembles[i]) * 0.5\n",
    "\n",
    "    # generate observation at k+1\n",
    "    y = observations[i+1]*torch.ones_like(mu)\n",
    "\n",
    "    # calculate lambda_k in step 2 of APF\n",
    "    tmp = y-mu\n",
    "    logits1 = -torch.einsum('ij,ij->i', tmp, tmp)/(2*noise_std**2)\n",
    "    logits1 = logits1 - logits1.max()\n",
    "    w1 = np.exp(logits1.cpu())\n",
    "    lam = w1/w1.sum()\n",
    "\n",
    "    # draw from the transition density in step 3 of APF\n",
    "    index_tmp = lam.multinomial(num_samples=n_resampling, replacement=True)\n",
    "    sample_tmp = mu[index_tmp]\n",
    "\n",
    "    # calculate the importance weight in step 4 of APF\n",
    "    tmp = y[index_tmp] - sample_tmp\n",
    "    logits2 = -torch.einsum('ij,ij->i', tmp, tmp)/(2*noise_std**2)\n",
    "    logits2 = logits2 - logits2.max()\n",
    "    w2 = np.exp(logits2.cpu())\n",
    "    w2 = w2/w2.sum()\n",
    "    \n",
    "    tmp = y[index_tmp]-sample_tmp\n",
    "    logits3 = -torch.einsum('ij,ij->i', tmp, tmp)/(2*noise_std**2)\n",
    "    logits3 = logits3 - logits3.max()\n",
    "    w3 = np.exp(logits3.cpu())\n",
    "    w3 = w3/w3.sum()\n",
    "    \n",
    "    ww = w2/w3\n",
    "    w = ww/ww.sum()\n",
    "    \n",
    "    # resampling the posterior samples as in step 5 of APF\n",
    "    index_res = w.multinomial(num_samples=n_ensemble, replacement=True)\n",
    "    ensembles[i+1] = sample_tmp[index_res]\n",
    "\n",
    "np.savez(\n",
    "    f'../lorenz_results/apf_sigma{noise_std}_nensemble{n_ensemble}.npz',\n",
    "    assimilated_states=ensembles.cpu().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_estimation = torch.mean(ensembles, dim=1)\n",
    "# t = np.arange(steps+1) * dt\n",
    "# markevery=1\n",
    "\n",
    "# mpl.rcdefaults()\n",
    "# mpl.rc(\"mathtext\", fontset=\"cm\")\n",
    "# mpl.rc(\"font\", family=\"serif\", serif=\"DejaVu Serif\")\n",
    "# mpl.rc(\"figure\", dpi=600, titlesize=9)\n",
    "# mpl.rc(\"figure.subplot\", wspace=0.2, hspace=0.6)\n",
    "# mpl.rc(\"axes\", grid=False, labelsize=9, labelpad=0.5)\n",
    "# mpl.rc(\"axes.spines\", top=False, right=False)\n",
    "# mpl.rc(\"xtick\", labelsize=6, direction=\"out\")\n",
    "# mpl.rc(\"ytick\", labelsize=6, direction=\"out\")\n",
    "# mpl.rc(\"xtick.major\", pad=2)\n",
    "# mpl.rc(\"ytick.major\", pad=2)\n",
    "# mpl.rc(\"grid\", linestyle=\":\", alpha=0.8)\n",
    "# mpl.rc(\"lines\", linewidth=1, markersize=5, markerfacecolor=\"none\", markeredgecolor=\"auto\", markeredgewidth=0.5)\n",
    "# mpl.rc(\"scatter\", marker='o')\n",
    "# mpl.rc(\"legend\", fontsize=9)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(7, 4))\n",
    "# for i in range(3):\n",
    "#     ax = axes[i]\n",
    "#     for j in range(3):\n",
    "#         axj = ax[j]\n",
    "#         axj.scatter(t[::markevery], states.cpu()[:, j+3*i][::markevery], label='Truth', color='C0', marker='o', facecolors='none', s=4, linewidths=1.)\n",
    "#         axj.plot(t, mean_estimation.cpu()[:, j+3*i], label='APF', color='C1', markevery=markevery)\n",
    "#         axj.set_title(f\"$x_{{{i*3+j+1}}}$\")\n",
    "# axes[0][1].legend(bbox_to_anchor=(0.9, 1.3), loc='lower left', ncol=2)\n",
    "# plt.text(0.08, 0.5, 'State', transform=plt.gcf().transFigure, fontsize=9, rotation='vertical')\n",
    "# plt.text(0.43, 0.03, 'Time step', transform=plt.gcf().transFigure, fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
